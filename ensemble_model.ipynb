{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE for Ensemble Model: 9.513209111508864\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation RMSE for Ensemble Model: \u001b[39m\u001b[39m{\u001b[39;00mrmse_val_ensemble\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[39m# Note: You can adjust hyperparameters, add more base models, or experiment with different meta-models as needed.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m# Calculate RMSE for the test set\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m rmse_test \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred_ensemble, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     64\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRMSE for test set: \u001b[39m\u001b[39m{\u001b[39;00mrmse_test\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[39m# Calculate RMSE for the validation set\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "df_train = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Load the testing dataset\n",
    "df_test = pd.read_csv('test_cleaned.csv')\n",
    "\n",
    "# Combine training and testing data for preprocessing\n",
    "df_combined = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "# Data preprocessing\n",
    "X_combined = df_combined.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_combined['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split the data back into training and testing sets\n",
    "X_train_scaled = X_combined_scaled[:len(df_train)]\n",
    "X_test_scaled = X_combined_scaled[len(df_train):]\n",
    "\n",
    "# Target variable for training\n",
    "y_train = y_combined[:len(df_train)]\n",
    "\n",
    "# Base models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Stacking ensemble\n",
    "base_models = [('rf', rf_model), ('gb', gb_model)]\n",
    "ensemble_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance (you may need a separate validation set for this in a real scenario)\n",
    "# For this example, let's assume you have a validation set\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "y_pred_val_ensemble = ensemble_model.predict(X_val_split)\n",
    "rmse_val_ensemble = mean_squared_error(y_val_split, y_pred_val_ensemble, squared=False)\n",
    "print(f'Validation RMSE for Ensemble Model: {rmse_val_ensemble}')\n",
    "\n",
    "# Note: You can adjust hyperparameters, add more base models, or experiment with different meta-models as needed.\n",
    "# Calculate RMSE for the test set\n",
    "rmse_test = mean_squared_error(y_test, y_pred_ensemble, squared=False)\n",
    "print(f\"RMSE for test set: {rmse_test}\")\n",
    "\n",
    "# Calculate RMSE for the validation set\n",
    "rmse_val = mean_squared_error(y_val_split, y_pred_val_ensemble, squared=False)\n",
    "print(f\"RMSE for validation set: {rmse_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the training dataset\n",
    "df_train = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "# Load the testing dataset\n",
    "df_test = pd.read_csv('test_cleaned.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "X_train = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_train = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "X_test = df_test.copy()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Base models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Stacking ensemble\n",
    "base_models = [('rf', rf_model), ('gb', gb_model)]\n",
    "ensemble_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the ensemble model on the entire training data\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Save predictions with Id\n",
    "result_df = pd.DataFrame({'Id': df_test['Id'], 'CO2 Emissions(g/km)': y_pred_test})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "result_df.to_csv('ensemble_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set using Ensemble: 19.50849679504109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_combined_scaled, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model RandomForest\n",
    "rf_model = RandomForestRegressor(n_estimators=150, max_depth=30, random_state=42, min_samples_split=10, min_samples_leaf=2, bootstrap=True)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Gabungkan hasil prediksi\n",
    "ensemble_pred = 0.30 * rf_pred + 0.70 * gb_pred\n",
    "\n",
    "# Evaluasi RMSE\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Ensemble: {ensemble_rmse}\")\n",
    "# RMSE on the test set using Ensemble: 19.50849679504109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set using Stacking Ensemble: 19.50987184527166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_combined_scaled, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=150, max_depth=30, random_state=42, min_samples_split=10, min_samples_leaf=2, bootstrap=True)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1))\n",
    "]\n",
    "\n",
    "meta_model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
    "\n",
    "# Stacking ensemble with different weights\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "stacking_pred = stacking_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluasi RMSE\n",
    "stacking_rmse = mean_squared_error(y_test, stacking_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Stacking Ensemble: {stacking_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set using Gradient Boosting: 19.65937153473047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_combined_scaled, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluasi RMSE\n",
    "gb_rmse = mean_squared_error(y_test, gb_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Gradient Boosting: {gb_rmse}\")\n",
    "# RMSE on the test set using Gradient Boosting: 19.552591571981765\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set using Gradient Boosting: 19.65937153473047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_combined_scaled, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluasi RMSE\n",
    "gb_rmse = mean_squared_error(y_test, gb_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Gradient Boosting: {gb_rmse}\")\n",
    "# RMSE on the test set using Gradient Boosting: 19.552591571981765\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data training\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_train = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_train = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Model RandomForest\n",
    "rf_model = RandomForestRegressor(n_estimators=150, max_depth=30, random_state=42, min_samples_split=10, min_samples_leaf=2, bootstrap=True)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Membaca data test\n",
    "df_test = pd.read_csv('cleaned_test.csv')\n",
    "\n",
    "# Simpan kolom 'Id' untuk digunakan dalam penggabungan hasil prediksi\n",
    "test_ids = df_test['Id']\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_test = pd.get_dummies(df_test)\n",
    "\n",
    "# Standardize the data menggunakan scaler yang sama dari data training\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prediksi menggunakan model RandomForest\n",
    "rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Prediksi menggunakan model GradientBoosting\n",
    "gb_test_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Gabungkan hasil prediksi\n",
    "ensemble_test_pred = 0.3 * rf_test_pred + 0.7 * gb_test_pred\n",
    "\n",
    "# Buat DataFrame hasil prediksi untuk data test\n",
    "ensemble_result_df = pd.DataFrame({'Id': test_ids, 'CO2 Emissions(g/km)': ensemble_test_pred})\n",
    "\n",
    "# Simpan hasil prediksi dalam file CSV\n",
    "ensemble_result_df.to_csv('ensemble2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test set using Ensemble: 19.882205504901215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UsEr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+05, tolerance: 1.790e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_combined_scaled, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model RandomForest\n",
    "rf_model = RandomForestRegressor(n_estimators=150, max_depth=30, random_state=42, min_samples_split=10, min_samples_leaf=2, bootstrap=True)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Model Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.01, random_state=42)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "# Gabungkan hasil prediksi\n",
    "ensemble_pred = 0.4 * rf_pred + 0.4 * gb_pred + 0.2 * lasso_pred\n",
    "\n",
    "# Evaluasi RMSE\n",
    "ensemble_rmse = mean_squared_error(y_test, ensemble_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Ensemble: {ensemble_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/235.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/235.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/235.6 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 41.0/235.6 kB 487.6 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 163.8/235.6 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 235.6/235.6 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.11.0\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Melakukan resampling menggunakan SMOTE\u001b[39;00m\n\u001b[0;32m     27\u001b[0m smote \u001b[39m=\u001b[39m SMOTE(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m smote\u001b[39m.\u001b[39;49mfit_resample(X_combined_scaled, y_combined)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Split data\u001b[39;00m\n\u001b[0;32m     31\u001b[0m X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled \u001b[39m=\u001b[39m train_test_split(X_resampled, y_resampled, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\UsEr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\UsEr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\UsEr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:364\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    361\u001b[0m X_class \u001b[39m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_k_\u001b[39m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 364\u001b[0m nns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn_k_\u001b[39m.\u001b[39;49mkneighbors(X_class, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[:, \u001b[39m1\u001b[39m:]\n\u001b[0;32m    365\u001b[0m X_new, y_new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_samples(\n\u001b[0;32m    366\u001b[0m     X_class, y\u001b[39m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[39m1.0\u001b[39m\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m X_resampled\u001b[39m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32mc:\\Users\\UsEr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    806\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[0;32m    807\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[1;32m--> 808\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    810\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[0;32m    811\u001b[0m     )\n\u001b[0;32m    813\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    814\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data\n",
    "df_train = pd.read_csv('cleaned_train.csv')\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "# Membuang kolom 'Id'\n",
    "df_train = df_train.drop(['Id'], axis=1)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X_combined = df_train.drop(['CO2 Emissions(g/km)'], axis=1)\n",
    "y_combined = df_train['CO2 Emissions(g/km)']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_combined = pd.get_dummies(X_combined)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Melakukan resampling menggunakan SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_combined_scaled, y_combined)\n",
    "\n",
    "# Split data\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model RandomForest\n",
    "rf_model = RandomForestRegressor(n_estimators=150, max_depth=30, random_state=42, min_samples_split=10, min_samples_leaf=2, bootstrap=True)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "rf_pred = rf_model.predict(X_test_resampled)\n",
    "\n",
    "# Model GradientBoosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=10, random_state=42, learning_rate=0.1)\n",
    "gb_model.fit(X_train_resampled, y_train_resampled)\n",
    "gb_pred = gb_model.predict(X_test_resampled)\n",
    "\n",
    "# Gabungkan hasil prediksi\n",
    "ensemble_pred = 0.5 * rf_pred + 0.5 * gb_pred\n",
    "\n",
    "# Evaluasi RMSE\n",
    "ensemble_rmse = mean_squared_error(y_test_resampled, ensemble_pred, squared=False)\n",
    "print(f\"RMSE on the test set using Ensemble after resampling: {ensemble_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
